{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "np.set_printoptions(precision=3)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 1000)\n"
     ]
    }
   ],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "vect_train = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vect_train_dense = vect_train.todense()\n",
    "print(vect_train_dense.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532, 1000)\n"
     ]
    }
   ],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "vectorizer_test = TfidfVectorizer(max_features=1000)\n",
    "vect_test = vectorizer_test.fit_transform(newsgroups_test.data)\n",
    "vect_test_dense = vect_test.todense()\n",
    "print(vect_test_dense.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\n",
    "    def __init__(self, input_num, lr, steps, num_of_bit):\n",
    "        self.input_num = input_num\n",
    "        self.steps = steps\n",
    "        self.lr = lr\n",
    "        self.num_of_bit = num_of_bit\n",
    "        self.w = np.random.random_sample((self.num_of_bit, self.input_num))\n",
    "        self.b = np.random.random_sample((self.num_of_bit, 1))\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    \n",
    "    def change_label_to_1_and_m1s(self, labels, num_of_cls=20):\n",
    "        res = []\n",
    "        for label in labels:\n",
    "            tmp = [-1] * num_of_cls\n",
    "            tmp[label] = 1\n",
    "            res.append(tmp)\n",
    "        return np.array(res)\n",
    "    \n",
    "    def precision(self, a, b, num_of_bin, num_of_cls):\n",
    "        correct = 0\n",
    "        pred = a.tolist()\n",
    "        for i in range(len(pred)):\n",
    "            answer = pred[i].index(max(pred[i]))\n",
    "            if answer==int(b[i]):\n",
    "                correct+=1\n",
    "                    \n",
    "        return float(correct) / len(a)\n",
    "        \n",
    "           \n",
    "    def compute_unit(self, input_feature, w, b, threshold):\n",
    "        wx_plus_b = np.dot(w, input_feature)\n",
    "        y = np.sign(wx_plus_b)\n",
    "        return y\n",
    "    \n",
    "    def train(self, input_features, labels, num_of_bit, threshold, num_of_cls):\n",
    "        multi_cls_label = self.change_label_to_1_and_m1s(labels, num_of_cls)\n",
    "        for step in range(self.steps):\n",
    "            y = self.compute_unit(input_features, self.w, self.b, threshold)\n",
    "            self.w += self.lr * np.sign(multi_cls_label.T-y) * input_features.T\n",
    "#             if step % 20 == 0:\n",
    "            print('precision: ', self.precision(y.T, labels, num_of_bit, num_of_cls))\n",
    "        return self.w\n",
    "    \n",
    "    def test_all(self, input_features, labels, num_of_bit, threshold, num_of_cls, stored_w):\n",
    "        y = self.compute_unit(input_features, stored_w, self.b, threshold)\n",
    "        print('precision: ', self.precision(y.T, labels, num_of_bit, num_of_cls))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.04242531377054976\n",
      "precision:  0.04330917447410288\n",
      "precision:  0.04330917447410288\n",
      "precision:  0.04330917447410288\n",
      "precision:  0.04330917447410288\n",
      "precision:  0.04330917447410288\n",
      "precision:  0.0434859466148135\n",
      "precision:  0.04410464910730069\n",
      "precision:  0.04543044016263037\n",
      "precision:  0.04772847799186848\n",
      "precision:  0.0522361675799894\n",
      "precision:  0.062400565670850276\n",
      "precision:  0.08511578575216545\n",
      "precision:  0.13284426374403394\n",
      "precision:  0.1950680572741736\n",
      "precision:  0.26763302103588477\n",
      "precision:  0.36255966059748984\n",
      "precision:  0.42602085911260384\n",
      "precision:  0.47003712214954924\n",
      "precision:  0.511048258794414\n",
      "precision:  0.5273112957397914\n",
      "precision:  0.5466678451476047\n",
      "precision:  0.5586883507159272\n",
      "precision:  0.5735372105356196\n",
      "precision:  0.5820222732897296\n",
      "precision:  0.593777620646986\n",
      "precision:  0.6013788226975428\n",
      "precision:  0.6067703729892169\n",
      "precision:  0.6133993282658653\n",
      "precision:  0.6169347710800778\n",
      "precision:  0.6138412586176418\n",
      "precision:  0.6471628071415945\n",
      "precision:  0.6295739791408874\n",
      "precision:  0.6566201166696128\n",
      "precision:  0.6386777443874845\n",
      "precision:  0.6590949266395616\n",
      "precision:  0.6692593247304225\n",
      "precision:  0.668817394378646\n",
      "precision:  0.6676683754640269\n",
      "precision:  0.678186317836309\n",
      "precision:  0.6546756231217961\n",
      "precision:  0.6814566024394555\n",
      "precision:  0.6910906841081845\n",
      "precision:  0.707088562842496\n",
      "precision:  0.6952448294148842\n",
      "precision:  0.7156620116669613\n",
      "precision:  0.6807495138766131\n",
      "precision:  0.7137175181191444\n",
      "precision:  0.6515821106593601\n",
      "precision:  0.707353721053562\n",
      "precision:  0.6870249248718402\n",
      "precision:  0.70399505038006\n",
      "precision:  0.7017853986211773\n",
      "precision:  0.7421778327735549\n",
      "precision:  0.7288315361499028\n",
      "precision:  0.7410288138589358\n",
      "precision:  0.7201697012550822\n",
      "precision:  0.7343114725119321\n",
      "precision:  0.7092982146013789\n",
      "precision:  0.7275057450945731\n",
      "precision:  0.7451829591656355\n",
      "precision:  0.6954216015555948\n",
      "precision:  0.7222025808732544\n",
      "precision:  0.7301573272052324\n",
      "precision:  0.7009899239879795\n",
      "precision:  0.7220258087325437\n",
      "precision:  0.7043485946614814\n",
      "precision:  0.7363443521301043\n",
      "precision:  0.7141594484709209\n",
      "precision:  0.7132755877673679\n",
      "precision:  0.7245890047728478\n",
      "precision:  0.7074421071239173\n",
      "precision:  0.750132579105533\n",
      "precision:  0.7254728654764009\n",
      "precision:  0.7356372635672618\n",
      "precision:  0.7340463143008662\n",
      "precision:  0.7101820753049319\n",
      "precision:  0.7208767898179247\n",
      "precision:  0.6925932473042249\n",
      "precision:  0.7614459961110129\n",
      "precision:  0.6845501149018914\n",
      "precision:  0.7602969771963939\n",
      "precision:  0.7111543220788403\n",
      "precision:  0.7709916917093866\n",
      "precision:  0.7744387484532438\n",
      "precision:  0.7649814389252254\n",
      "precision:  0.7764716280714159\n",
      "precision:  0.7716103942018738\n",
      "precision:  0.7892876082729362\n",
      "precision:  0.7726710270461375\n",
      "precision:  0.7846031465441047\n",
      "precision:  0.7712568499204525\n",
      "precision:  0.7689588120912144\n",
      "precision:  0.7980378292381121\n",
      "precision:  0.7499558069648223\n",
      "precision:  0.7995403924341524\n",
      "precision:  0.7260915679688881\n",
      "precision:  0.7642743503623829\n",
      "precision:  0.7398797949443168\n",
      "precision:  0.7037298921689942\n",
      "precision:  0.6802191974544812\n",
      "precision:  0.7389075481704084\n",
      "precision:  0.7264451122503094\n",
      "precision:  0.7793883683931413\n",
      "precision:  0.7207884037475694\n",
      "precision:  0.7758529255789287\n",
      "precision:  0.705939543927877\n",
      "precision:  0.7784161216192328\n",
      "precision:  0.7188439101997525\n",
      "precision:  0.7915856461021743\n",
      "precision:  0.6899416651935655\n",
      "precision:  0.7784161216192328\n",
      "precision:  0.732013434682694\n",
      "precision:  0.7754993812975075\n",
      "precision:  0.7455365034470568\n",
      "precision:  0.7967120381827824\n",
      "precision:  0.8047551705851158\n",
      "precision:  0.8242884921336397\n",
      "precision:  0.8116492840728301\n",
      "precision:  0.8335690295209475\n",
      "precision:  0.7777090330563903\n",
      "precision:  0.8333922573802369\n",
      "precision:  0.7912321018207531\n",
      "precision:  0.8010429556301927\n",
      "precision:  0.703111189676507\n",
      "precision:  0.7885805197100937\n",
      "precision:  0.6827823934947852\n",
      "precision:  0.7881385893583172\n",
      "precision:  0.7662188439101998\n",
      "precision:  0.7109775499381298\n",
      "precision:  0.7687820399505038\n",
      "precision:  0.7230864415768075\n",
      "precision:  0.7475693830652289\n",
      "precision:  0.7869895704436981\n",
      "precision:  0.766572388191621\n",
      "precision:  0.7709033056390313\n",
      "precision:  0.7701078310058335\n",
      "precision:  0.7912321018207531\n",
      "precision:  0.8155382711684639\n",
      "precision:  0.832861940958105\n",
      "precision:  0.8001590949266396\n",
      "precision:  0.7991868481527311\n",
      "precision:  0.797153968534559\n",
      "precision:  0.7733781156089801\n",
      "precision:  0.8048435566554711\n",
      "precision:  0.7257380236874669\n",
      "precision:  0.8143008661834895\n",
      "precision:  0.7838960579812622\n",
      "precision:  0.7821283365741559\n",
      "precision:  0.7346650167933534\n",
      "precision:  0.7612692239703023\n",
      "precision:  0.8161569736609511\n",
      "precision:  0.7986565317305993\n",
      "precision:  0.8044016263036945\n",
      "precision:  0.7819515644334453\n",
      "precision:  0.8346296623652112\n",
      "precision:  0.7818631783630899\n",
      "precision:  0.8431147251193212\n",
      "precision:  0.8049319427258264\n",
      "precision:  0.8172176065052148\n",
      "precision:  0.8593777620646986\n",
      "precision:  0.8181898532791232\n",
      "precision:  0.8329503270284603\n",
      "precision:  0.8261445996111013\n",
      "precision:  0.8089093158918155\n",
      "precision:  0.752695775145837\n",
      "precision:  0.7767367862824819\n",
      "precision:  0.774792292734665\n",
      "precision:  0.7932649814389252\n",
      "precision:  0.7922043485946615\n",
      "precision:  0.7144246066819869\n",
      "precision:  0.8006894113487715\n",
      "precision:  0.7151316952448294\n",
      "precision:  0.7978610570974014\n",
      "precision:  0.7015202404101114\n",
      "precision:  0.8154498850981086\n",
      "precision:  0.7536680219197455\n",
      "precision:  0.815007954746332\n",
      "precision:  0.7958281774792293\n",
      "precision:  0.8010429556301927\n",
      "precision:  0.8495669082552589\n",
      "precision:  0.7975958988863355\n",
      "precision:  0.8670673501856108\n",
      "precision:  0.8020152024041011\n",
      "precision:  0.8475340286370868\n",
      "precision:  0.8368393141240941\n",
      "precision:  0.8415237758529256\n",
      "precision:  0.8462966236521124\n",
      "precision:  0.8027222909669436\n",
      "precision:  0.8287961817217606\n",
      "precision:  0.7771787166342584\n",
      "precision:  0.7630369453774085\n",
      "precision:  0.7217606505214779\n",
      "precision:  0.7743503623828885\n",
      "precision:  0.7911437157503978\n",
      "precision:  0.788668905780449\n",
      "precision:  0.7985681456602439\n",
      "precision:  0.8340109598727241\n",
      "precision:  0.8455011490189146\n",
      "precision:  0.8209298214601379\n"
     ]
    }
   ],
   "source": [
    "num_of_cls = len(newsgroups_train.target_names)\n",
    "model = Perceptron(int(vect_train.shape[1]), lr=0.1, steps=200, num_of_bit=num_of_cls)\n",
    "weight_list = model.train(vect_train_dense.T, newsgroups_train.target, num_of_bit=5, threshold=0.5, num_of_cls=num_of_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.5683224323846562\n"
     ]
    }
   ],
   "source": [
    "num_of_cls = len(newsgroups_test.target_names)\n",
    "test_acc = model.test_all(vect_test_dense.T, newsgroups_test.target, 5, 0.5, num_of_cls, weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
